{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/pui-sum-rv/lab3/blob/main/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vtuqXEBP1j"
      },
      "source": [
        "# Lab 3 - Thresholding and Binary Morphology\n",
        "\n",
        "These laboratory excersises are solved on Google Colab and are save on GitHub repo that is connected to GitHub Classroom.\n",
        "\n",
        "## Tools You need to use to Submit Assignments\n",
        "\n",
        "In this document, you will solve tasks. This is a Jupyter Notebook which has the **.ipynb** extension, is an interactive web environment for data analysis, visualization, solution presentations, education, and more.\n",
        "\n",
        "**Google Colab** is a tool that allows you to run and share Jupyter Notebook files on Google's servers, including the use of Google's CPU, GPU, and TPU resources. Colab is like Google Docs for Jupyter Notebooks. **Google Colab does not automatically save your assignment to GitHub.**\n",
        "\n",
        "**You use GitHub to save and submit your assignments.** When you accept the assignment through GitHub Classroom, a repository is automatically created on your GitHub account with a copy of the task. This is where you will save your solutions. Saving your solutions submits the tasks for that lab.\n",
        "\n",
        "## How to Solve the Tasks?\n",
        "1. Accept the task via the Google Classroom link that you will receive. Google Classroom will create a repository on your account.\n",
        "2. Go to the newly created repository on your account and click on the .ipynb file, then click Open in Colab.\n",
        "3. You will solve the tasks in Google Colab.\n",
        "\n",
        "## How to Save (Submit) Tasks?\n",
        "\n",
        "1. In Google Colab, click on the Open settings gear icon in the top-right corner.\n",
        "2. Click on the GitHub tab and check the box for Access private repositories and organizations.\n",
        "3. A new window will open for you to grant access to GitHub. For ferit-osirv, click Grant.\n",
        "4. Save and exit the settings.\n",
        "5. Click on File > Save a copy in GitHub.\n",
        "6. Select the lab repository that includes your name.\n",
        "\n",
        "> *Note:* You only need to complete steps 1-4 the first time.\n",
        "\n",
        "7. Click on **File > Save a copy in GitHub**.\n",
        "8. Select created repository **koji uključuje vaše ime**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUPz7IDCbDx"
      },
      "source": [
        "## Copying Files from a GitHub Repository\n",
        "\n",
        "To complete the exercises, you will need images and other files that are located in the GitHub repository of the exercise. This command will be available in the notebook for each exercise. It will copy files from GitHub to the Google Colab environment.\n",
        "\n",
        "**You need to run this command before starting each exercise.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpP_i0KgCefb",
        "outputId": "e08a0979-cb3c-41f4-be61-07957597ae31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'clone'...\n",
            "remote: Repository not found.\n",
            "fatal: repository 'https://github.com/ferit-osirv/lab2/' not found\n"
          ]
        }
      ],
      "source": [
        "!rm -rf clone && git clone https://github.com/ferit-osirv/lab2 clone && cp -a clone/. ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIPg8Vf9Cr8D"
      },
      "source": [
        "**Google Colab will occasionally delete all files.** Therefore, it may be necessary to rerun this command between sessions. If you are getting errors about missing files, try running the above command again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXS_YJC2WsWD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFGMN-oF45DB"
      },
      "source": [
        "# Thresholding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqV9LNMO45DB"
      },
      "source": [
        "## What is Thresholding?\n",
        "\n",
        "The simplest segmentation method\n",
        "\n",
        "Application example: Separate out regions of an image corresponding to\n",
        "objects which we want to analyze. This separation is based on the variation\n",
        "of intensity between the object pixels and the background pixels.\n",
        "\n",
        "To differentiate the pixels we are interested in from the rest (which will\n",
        "eventually be rejected), we perform a comparison of each pixel intensity\n",
        "value with respect to a threshold (determined according to the problem to\n",
        "solve).\n",
        "\n",
        "Once we have separated properly the important pixels, we can set them with\n",
        "a determined value to identify them (i.e. we can assign them a value of 0\n",
        "(black), 255 (white) or any value that suits your needs).\n",
        "\n",
        "![](https://docs.opencv.org/2.4/_images/Threshold_Tutorial_Theory_Example.jpg)\n",
        "\n",
        "\n",
        "## Simple Thresholding\n",
        "\n",
        "Here, the matter is straight forward. If pixel value is greater than a\n",
        "threshold value, it is assigned one value (may be white), else it is assigned\n",
        "another value (may be black). The function used is `cv2.threshold`. First\n",
        "argument is the source image, which should be a grayscale image. Second\n",
        "argument is the threshold value which is used to classify the pixel values.\n",
        "Third argument is the ` maxVal ` which represents the value to be given if pixel\n",
        "value is more than (sometimes less than) the threshold value. OpenCV provides\n",
        "different styles of thresholding and it is decided by the fourth parameter of\n",
        "the function. Different types are:\n",
        "\n",
        "- cv2.THRESH_BINARY\n",
        "- cv2.THRESH_BINARY_INV\n",
        "- cv2.THRESH_TRUNC\n",
        "- cv2.THRESH_TOZERO\n",
        "- cv2.THRESH_TOZERO_INV\n",
        "\n",
        "To illustrate how these thresholding processes work, let’s consider that we\n",
        "have a source image with pixels with intensity values $` src(x,y) `$.\n",
        "The plot below\n",
        "depicts this. The horizontal blue line represents the threshold $` thresh `$ (fixed).\n",
        "\n",
        "![](https://docs.opencv.org/2.4/_images/Threshold_Tutorial_Theory_Base_Figure.png)\n",
        "\n",
        "The documentation clearly explains what each type is meant for. [Please check out the\n",
        "documentation](http://docs.opencv.org/doc/tutorials/imgproc/threshold/threshold.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BzP0PaQ45DC"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Using OpenCV, load the image `images/apple.jpg` as a **grayscale** image. Perform simple **binary** thresholding in two ways: 1) using the OpenCV function mentioned above, and 2) using NumPy by setting all pixels above a certain value to 255 and others to 0. Display the thresholded image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dlIt4WK45DC"
      },
      "outputs": [],
      "source": [
        "# opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6cO-OM345DC"
      },
      "outputs": [],
      "source": [
        "# numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "255zc1Fc45DC"
      },
      "source": [
        "### ### Otsu Binarization\n",
        "\n",
        "**Binarization** of an image is the process of converting the image into a format where each pixel can only be one of two possible values. For `uint8` images, these values are usually `0` (black) and `255` (white). For `float` images, the values are `0` (black) or `1.0` (white). **Binarization** is often a precursor to **thresholding**, where the image is divided into completely white and black regions, and then only the parts of the original image that are completely white in the binary image are retained. Mathematically, by multiplying the original and binary images, the pixels that are completely white in the binary image remain unchanged, while those that are completely black are multiplied by 0, resulting in a completely black pixel in the product image.\n",
        "\n",
        "In the previous example, you manually determined the threshold. Otsu binarization is a more advanced method that determines the optimal threshold based on the **histogram** of the image, which best separates the pixels. A histogram is a graph that shows the frequency of each value in a data set. In the case of an image, the histogram shows, for each color value, how many pixels are of that color.\n",
        "\n",
        "Let's take a look at the histogram of the `apple.jpg` image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBZ3rgot45DC",
        "outputId": "04a8aca6-a860-4358-9cdf-734117e6716a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "img = cv.imread('images/apple.jpg', cv.IMREAD_GRAYSCALE)\n",
        "plt.hist(img.flatten(), bins=256, range=(0, 255))\n",
        "plt.ylim([0, 10000])\n",
        "plt.xlim([0, 255])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8GLGjSy45DD"
      },
      "source": [
        "From the histogram, it is evident that most pixels are grouped around the values 255 and 50. By approximation, we see that the optimal way to separate the pixels into two groups would be with a threshold between 150 and 200, as this threshold effectively separates the two largest groups of pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZRtn39m45DD"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "According to the [following link](https://learnopencv.com/otsu-thresholding-with-opencv/), implement Otsu binarization for the `apple.jpg` image. Display the resulting binary image **using Matplotlib**. Print the optimal threshold value determined by the Otsu method to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt1Q4F_H45DD"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbohx7ZX45DD"
      },
      "source": [
        "Such a binary image can be used as a **mask** for the original image. A mask is a binary image where the value is `0` for all pixels that should not be visible, and the maximum value (`1.0` or `255`) for pixels that should be visible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PRILBvi45DD"
      },
      "source": [
        "## Task 5\n",
        "\n",
        "Using the Otsu binary image as a mask, apply the function `img_thresholded = cv.bitwise_and(img, img, mask=mask)` where `img` is the original grayscale image of the apple, and `mask` is the Otsu binary image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsWJwkSz45DD"
      },
      "source": [
        "## Improving Masks with Binary Morphology\n",
        "\n",
        "Morphological transformations are some simple operations based on the image shape. It is normally performed on binary images. It needs two inputs, one is our original image, second one is called structuring element or kernel which decides the nature of operation. Two basic morphological operators are `erosion` and `dilation`. Then its variant forms like `opening`, `closing`, `gradient` etc. also comes into play.\n",
        "\n",
        "Morphological operations such as `erosion`, `dilation`, `closing` and `opening` are common tools used to improve masks after they are generated by thresholding. They can be used to fill small holes, remove noise, increase or decrease the size of an object, or smoothen mask outlines.\n",
        "\n",
        "Most morphological operations are once again simple kernel functions that are applied at each pixel of the image based on their neighborhood as defined by a `structuring element (SE)`. For example, `dilation` simply assigns to the central pixel the maximum pixel value within the neighborhood; it is a maximum filter. Conversely, `erosion` is a minimum filter. Additional options emerge from combining the two: `morphological closing`, for example, is a `dilation` followed by an `erosion`. This is used to fill in gaps and holes or smoothing mask outlines without significantly changing the mask's area. Finally, there are also some more complicated morphological operations, such as `hole filling`.\n",
        "\n",
        "Images can be thought to be a mapping from the integer space $\\mathbb{Z^2}$ to $\\mathbb{R}$. For a binary image, the mapping reduces to $f: \\mathbb{Z^2} \\to \\{0,1\\}$. Every pixel at position $(x,y)\\in\\mathbb{Z^2}$ is either completely dark $(0)$ or completely bright $(1)$. We shall now introduce two very important set operations.\n",
        "\n",
        "Reflection of a set $B\\subseteq\\mathbb{Z}^2$ is defined as $\\hat{B} = \\{w : w=-b, \\forall b\\in B\\}$. E.g. if $B$ is a set of points of the form $(x,y)$, then $\\hat{B}$ can be found by replacing those points by $(-x,-y)$.\n",
        "\n",
        "Translation of a set $B\\subseteq\\mathbb{Z}^2$ by a point $z=(z_1,z_2)$ is defined as $(B)_z=\\{c : c=b+z,\\forall b\\in B\\}$. E.g. if $B$ is a set of points of the form $(x,y)$, then $(B)_z$ can be found by replacig those points by $(x+z_1, y+z_2)$.\n",
        "\n",
        "Set reflection and translation are employed extensively in morphology to formulate operations based on so-called structuring elements (SEs) or kernels. SEs are basically small sets or subimages used to probe an image under study for properties of interest. Usually they are often taken in rectangular, circular, elliptical or cross shapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBvuQrg86ewm"
      },
      "source": [
        "### Erosion\n",
        "\n",
        "With $A, B \\subseteq \\mathbb{Z}^2$, the erosion of $A$ by $B$ (SE) is defined as $A\\ominus B = \\{z : (B)_z \\subseteq A\\}$. In words, this equation indicated that the erosion of $A$ by $B$ is the set of all points $z$ such that $B$, translated by $z$, is contained in $A$. The basic idea of erosion is just like soil erosion only, it erodes away the boundaries of foreground object (Always try to keep foreground in white). So what does it do? The kernel (SE) slides through the image (as in 2D convolution). A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
        "\n",
        "So what happends is that, all the pixels near boundary will be discarded depending upon the size of kernel. So the thickness or size of the foreground object decreases or simply white region decreases in the image. It is useful for removing small white noises, detach two connected objects etc. Let us use a rectangular SE (kernel) to check this out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcqrlbQe60DV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import cv2\n",
        "import skimage as sk\n",
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jld8kei62-s"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.png',0)\n",
        "kernel1 = np.ones((3,3), np.uint8)\n",
        "erosion1 = cv2.erode(img, kernel1, iterations = 1)\n",
        "kernel2 = np.ones((5,5), np.uint8)\n",
        "erosion2 = cv2.erode(img, kernel2, iterations = 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(erosion1, cmap=plt.cm.gray)\n",
        "plt.title(r'Erosion with a $3\\times3$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(erosion2, cmap=plt.cm.gray)\n",
        "plt.title(r'Erosion with a $5\\times5$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxADFInb8MSD"
      },
      "source": [
        "### Dilation\n",
        "\n",
        "With $A, B \\subseteq \\mathbb{Z}^2$, the dilation of $A$ by $B$ (SE) is defined as $A\\oplus B = \\{z:(\\hat{B})_z\\cap A \\ne \\phi\\}$. In words, the dilation of $A$ by $B$ is the set consisting of all the structuring element origin locations where the reflected and translated $B$ overlaps at least one element of $A$.\n",
        "\n",
        "It is just opposite of erosion. Here, a pixel element is $1$ if atleast one pixel under the kernel is $1$. So it increases the white region in the image or size of foreground object increases. Normally, in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object. So we dilate it. Since noise is gone, they won’t come back, but our object area increases. It is also useful in joining broken parts of an object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY5l12Uu8Rtg"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.png',0)\n",
        "kernel1 = np.ones((3,3), np.uint8)\n",
        "dilation1 = cv2.dilate(img, kernel1, iterations = 1)\n",
        "kernel2 = np.ones((5,5), np.uint8)\n",
        "dilation2 = cv2.dilate(img, kernel2, iterations = 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(dilation1, cmap=plt.cm.gray)\n",
        "plt.title(r'Dilation with a $3\\times3$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(dilation2, cmap=plt.cm.gray)\n",
        "plt.title(r'Dilation with a $5\\times5$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1N_6day8Uu4"
      },
      "source": [
        "### Opening\n",
        "\n",
        "The morphological opening of $A$ by $B$ is defined as $A \\circ B = (A\\ominus B)\\oplus B = \\cup\\{(B)_z:(B)_z\\subseteq A\\}$, which is nothing but erosion followed by dilation. It is useful in removing noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoTF18zA8ZQ3"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.png',0)\n",
        "kernel1 = np.ones((5,5), np.uint8)\n",
        "opening1 = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel1)\n",
        "kernel2 = np.ones((7,7), np.uint8)\n",
        "opening2 = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(opening1, cmap=plt.cm.gray)\n",
        "plt.title(r'Opening with a $5\\times5$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(opening2, cmap=plt.cm.gray)\n",
        "plt.title(r'Opening with a $7\\times7$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGysvaMT8pip"
      },
      "source": [
        "### Closing\n",
        "\n",
        "The morphological closing of $A$ by $B$ is defined as $A \\bullet B = (A\\oplus B)\\ominus B$, which is nothing but dilation followed by erosion. It is useful in removing noise. It is useful in closing small holes inside the foreground objects, or small black points on the object.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxeGpN_08r5G"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.jpg',0)\n",
        "kernel1 = np.ones((5,5), np.uint8)\n",
        "closing1 = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel1)\n",
        "kernel2 = np.ones((7,7), np.uint8)\n",
        "closing2 = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(closing1, cmap=plt.cm.gray)\n",
        "plt.title(r'Closing with a $5\\times5$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(closing2, cmap=plt.cm.gray)\n",
        "plt.title(r'Closing with a $7\\times7$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoxFJrut8uYx"
      },
      "source": [
        "### Morphological Gradient\n",
        "\n",
        "It is the difference between dilation and erosion of an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNO_DuHe8xnY"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.jpg',0)\n",
        "kernel1 = np.ones((3,3), np.uint8)\n",
        "grad1 = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel1)\n",
        "kernel2 = np.ones((5,5), np.uint8)\n",
        "grad2 = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(grad1, cmap=plt.cm.gray)\n",
        "plt.title(r'Morphological gradient with a $3\\times3$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(grad2, cmap=plt.cm.gray)\n",
        "plt.title(r'Morphological gradient with a $5\\times5$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVQiNrEk8zPY"
      },
      "source": [
        "### Tophat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiZKtDZ180Tb"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.png',0)\n",
        "kernel1 = np.ones((5,5), np.uint8)\n",
        "top1 = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel1)\n",
        "kernel2 = np.ones((9,9), np.uint8)\n",
        "top2 = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(top1, cmap=plt.cm.gray)\n",
        "plt.title(r'Morphological tophat with a $5\\times5$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(top2, cmap=plt.cm.gray)\n",
        "plt.title(r'Morphological tophat with a $9\\times9$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BieKTkb682lo"
      },
      "source": [
        "### Blackhat\n",
        "\n",
        "It is the difference between the closing of the input image and input image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUf54wTs84oh"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.jpg',0)\n",
        "kernel1 = np.ones((5,5), np.uint8)\n",
        "black1 = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel1)\n",
        "kernel2 = np.ones((11,11), np.uint8)\n",
        "black2 = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(black1, cmap=plt.cm.gray)\n",
        "plt.title(r'Morphological blackhat with a $5\\times5$ kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(black2, cmap=plt.cm.gray)\n",
        "plt.title(r'Morphological blackhat with a $11\\times11$ kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyrV5yXQ87Cx"
      },
      "source": [
        "### SEs of different shapes\n",
        "\n",
        "OpenCV provides built-in functions for creating SEs of custom shapes like circle, ellipse, cross, etc. They turn out to be useful for dufferent purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stDXLqLA8-jJ"
      },
      "outputs": [],
      "source": [
        "# Rectangular Kernel\n",
        "rect = cv2.getStructuringElement(cv2.MORPH_RECT,(25,25))\n",
        "# Elliptical Kernel\n",
        "ellip = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(25,25))\n",
        "# Cross-shaped Kernel\n",
        "cross = cv2.getStructuringElement(cv2.MORPH_CROSS,(25,25))\n",
        "\n",
        "plt.matshow(ellip, cmap=cm.gray)\n",
        "plt.title(r'A $19\\times 19$ elliptical / circular kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlNwt4FQ9AOQ"
      },
      "source": [
        "Now check the morphological closing operation with circular SEs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6OYacAi9BiZ"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.jpg',0)\n",
        "kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
        "closing1 = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel1)\n",
        "kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))\n",
        "closing2 = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(closing1, cmap=plt.cm.gray)\n",
        "plt.title(r'Closing with a $5\\times5$ circular kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(closing2, cmap=plt.cm.gray)\n",
        "plt.title(r'Closing with a $15\\times15$ circular kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3irM2CyJ9Csx"
      },
      "source": [
        "Another example showing morphological blackhat operation with circular SEs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GrreRYy9EU6"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('images/binary_image.jpg',0)\n",
        "kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
        "black1 = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel1)\n",
        "kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))\n",
        "black2 = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel2)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plt.imshow(img, cmap=plt.cm.gray)\n",
        "plt.title('Original image')\n",
        "plt.subplot(132)\n",
        "plt.imshow(black1, cmap=plt.cm.gray)\n",
        "plt.title(r'Blackhat with a $9\\times9$ circular kernel')\n",
        "plt.subplot(133)\n",
        "plt.imshow(black2, cmap=plt.cm.gray)\n",
        "plt.title(r'Blackhat with a $15\\times15$ circular kernel')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tasks\n",
        "\n",
        "1. Study previous examples and try different combinations of SE element. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
